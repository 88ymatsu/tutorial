{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/88ymatsu/tutorial/blob/master/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4191gkI_fJE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "class Predictor(nn.Module):\n",
        "    def __init__(self, inputDim, hiddenDim, outputDim):\n",
        "        super(Predictor, self).__init__()\n",
        "\n",
        "        self.rnn = nn.LSTM(input_size = inputDim,\n",
        "                            hidden_size = hiddenDim,\n",
        "                            batch_first = True)\n",
        "        self.output_layer = nn.Linear(hiddenDim, outputDim)\n",
        "    \n",
        "    def forward(self, inputs, hidden0=None):\n",
        "        output, (hidden, cell) = self.rnn(inputs, hidden0)\n",
        "        output = self.output_layer(output[:, -1, :])\n",
        "\n",
        "        return output\n",
        "\n",
        "def mkDataSet(data_size, data_length=50, freq=60., noise=0.00):\n",
        "    \"\"\"\n",
        "    params\\n\n",
        "    data_size : データセットサイズ\\n\n",
        "    data_length : 各データの時系列長\\n\n",
        "    freq : 周波数\\n\n",
        "    noise : ノイズの振幅\\n\n",
        "    returns\\n\n",
        "    train_x : トレーニングデータ（t=1,2,...,size-1の値)\\n\n",
        "    train_t : トレーニングデータのラベル（t=sizeの値）\\n\n",
        "    \"\"\"\n",
        "    train_x = []\n",
        "    train_t = []\n",
        "\n",
        "    for offset in range(data_size):\n",
        "        train_x.append([[math.sin(2 * math.pi * (offset + i) / freq) + np.random.normal(loc=0.0, scale=noise)] for i in range(data_length)])\n",
        "        train_t.append([math.sin(2 * math.pi * (offset + data_length) / freq)])\n",
        "\n",
        "    return train_x, train_t\n",
        "\n",
        "def mkRandomBatch(train_x, train_t, batch_size=10):\n",
        "    \"\"\"\n",
        "    train_x, train_tを受け取ってbatch_x, batch_tを返す。\n",
        "    \"\"\"\n",
        "    batch_x = []\n",
        "    batch_t = []\n",
        "\n",
        "    for _ in range(batch_size):\n",
        "        idx = np.random.randint(0, len(train_x) - 1)\n",
        "        batch_x.append(train_x[idx])\n",
        "        batch_t.append(train_t[idx])\n",
        "    \n",
        "    return torch.tensor(batch_x), torch.tensor(batch_t)\n",
        "\n",
        "def main():\n",
        "    training_size = 10000\n",
        "    test_size = 1000\n",
        "    epochs_num = 200\n",
        "    hidden_size = 3\n",
        "    batch_size = 100\n",
        "\n",
        "    train_x, train_t = mkDataSet(training_size)\n",
        "    test_x, test_t = mkDataSet(test_size)\n",
        "\n",
        "    model = Predictor(1, hidden_size, 1)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    for epoch in range(epochs_num):\n",
        "        # training\n",
        "        running_loss = 0.0\n",
        "        training_accuracy = 0.0\n",
        "        for i in range(int(training_size / batch_size)):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            data, label = mkRandomBatch(train_x, train_t, batch_size)\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.data.item()\n",
        "            training_accuracy += np.sum(np.abs((output.data - label.data).numpy()) < 0.1)\n",
        "\n",
        "        #test\n",
        "        test_accuracy = 0.0\n",
        "        for i in range(int(test_size / batch_size)):\n",
        "            offset = i * batch_size\n",
        "            data, label = torch.tensor(test_x[offset:offset+batch_size]), torch.tensor(test_t[offset:offset+batch_size])\n",
        "            output = model(data, None)\n",
        "\n",
        "            test_accuracy += np.sum(np.abs((output.data - label.data).numpy()) < 0.1)\n",
        "        \n",
        "        training_accuracy /= training_size\n",
        "        test_accuracy /= test_size\n",
        "\n",
        "        print('%d loss: %.3f, training_accuracy: %.5f, test_accuracy: %.5f' % (\n",
        "            epoch + 1, running_loss, training_accuracy, test_accuracy))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}